{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os seguintes scripts são uma versão Python do curso de Machine Learning do professor Andrew Ng da universidade de Stanford leccionado na plataforma Coursera.\n",
    "\n",
    "**Nota: Todos os dados e estrutura do exercício pertencem à Universidade de Stanford**\n",
    "\n",
    "**Ressalva:** Os scripts não estão implementados de forma modular para todas as funções serem consultadas no mesmo Jupyter Notebook - ao contrário da implementação Octave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1 - Gerar Features E-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o numpy para lidar com matrizes e vectores\n",
    "import numpy as np\n",
    "# Importar o pandas para ler ficheiros\n",
    "import pandas as pd\n",
    "# Importar o matplotlib como ferramenta gráfica\n",
    "import matplotlib.pyplot as plt\n",
    "# Importar a library de expressões regulares\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Importar o tokenizer do NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Importar o stemmer\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Importar o módulo de matemática\n",
    "import math \n",
    "\n",
    "# Importar a função de optimização do scipy\n",
    "from scipy import optimize, io\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "# Importar a biblioteca da classe de modelos SVM\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ivobernardo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Download punkt if you need to\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos muitos problemas que podemos resolver com machine learning é a classificação de e-mails de spam.\n",
    "Neste exercício vamos usar uma Suppor Vector Machine (Máquina de Vectores Suporte) para resolver o problema. \n",
    "<br> \n",
    "<br>\n",
    "Vamos analisar os dados primeiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o contéudo de um e-mail para demonstração\n",
    "conteudo_ficheiro = open(\"emailSample1.txt\", \"r\")\n",
    "conteudo_ficheiro = (conteudo_ficheiro.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conteudo_ficheiro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como conseguimos transformar este ficheiro em algo que a Support Vector Machine pode entender? Grande parte dos algoritmos apenas compreende dados tabulares e é necessário transformar qualquer input num formato semelhante.\n",
    "<br> \n",
    "Precisamos de transformar estas palavras em números, de alguma forma - vamos começar por ler uma lista com vocabulário (conjunto de palavras onde apenas temos as palavras mais comuns de todos os e-mails que vamos analisar à frente) e pré-processar os dados e depois criar um vector de palavras com base nessa lista. Antes de criarmos o nosso vector de palavras para cada e-mail vamos realizar algumas tarefas de pré-processamento de Linguagem Natural como: \n",
    "<br>\n",
    "- Manter apenas caracteres alfanuméricos.\n",
    "- Mapear e-mails ou urls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterVocabulario(\n",
    ")-> dict:\n",
    "    '''\n",
    "    Lê um ficheiro de vocabulário e \n",
    "    mapeia-o para um dicionário onde\n",
    "    cada palavra terá um número associado.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        vocab_dict(dict): Dicionário de palavras.\n",
    "    '''\n",
    "    vocab_dict = {}\n",
    "    \n",
    "    with open(\"vocab.txt\", \"r\") as vocab:\n",
    "        for linha in vocab:\n",
    "            vocab_dict[int((linha.split('\\t'))[0]),1] = linha.split('\\t')[1].replace('\\n','')\n",
    "            \n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processarEmail(\n",
    "    conteudo_email: str\n",
    ") -> list:\n",
    "    '''\n",
    "    Processo o email e devolve o vector de palavras \n",
    "    com base no vocabulario.\n",
    "    \n",
    "    Args:\n",
    "        conteudo_email(str): Conteúdo do e-mail.\n",
    "    Return:\n",
    "        indice_palavras(list): Lista com os índices \n",
    "        de palavras do contéudo do e-mail.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    listaVocabulario = obterVocabulario()\n",
    "    indice_palavras = []\n",
    "    # Colocar o e-mail em minúsculas\n",
    "    conteudo_email = conteudo_email.lower()\n",
    "    # Substituir as tags \\n\n",
    "    conteudo_email = conteudo_email.replace('\\n',' ')\n",
    "    # Reter alfanuméricos\n",
    "    conteudo_email = re.sub('<[^<>]+>', ' ', conteudo_email)\n",
    "    # Substituir os números \n",
    "    conteudo_email = re.sub('[0-9]+', 'number', conteudo_email)\n",
    "    # Substituir os URLS\n",
    "    conteudo_email = re.sub('(http|https)://[^\\s]*', 'httpaddr', conteudo_email)\n",
    "    # Substituir os campos de e-mail\n",
    "    conteudo_email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', conteudo_email)\n",
    "    # Substituir o símbolo de dollar\n",
    "    conteudo_email = re.sub('[$]+', 'dollar', conteudo_email)\n",
    "    # Criar uma lista de palavras\n",
    "    conteudo_email = word_tokenize(conteudo_email)\n",
    "    \n",
    "    conteudo_processado = []\n",
    "    \n",
    "    for el in conteudo_email:\n",
    "        # Remover a pontuação\n",
    "        element = (el.translate(str.maketrans('', '', string.punctuation)))\n",
    "        element = re.sub(r'\\W+', '', element)\n",
    "        if len(element)>=1:\n",
    "            conteudo_processado.append(stemmer.stem(element))\n",
    "\n",
    "    # Pesquisar no vocabulário pelo índice correspondente\n",
    "    for el in conteudo_processado:\n",
    "        try:\n",
    "            indice_palavras.append([k for k,v in listaVocabulario.items() if v == el][0][0])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return indice_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o vector de índices com as palavras do e-mail\n",
    "indice_palavras = processarEmail(conteudo_ficheiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86,\n",
       " 916,\n",
       " 794,\n",
       " 1077,\n",
       " 883,\n",
       " 370,\n",
       " 1699,\n",
       " 790,\n",
       " 1822,\n",
       " 1831,\n",
       " 883,\n",
       " 431,\n",
       " 1171,\n",
       " 794,\n",
       " 1002,\n",
       " 1893,\n",
       " 1364,\n",
       " 592,\n",
       " 1676,\n",
       " 238,\n",
       " 162,\n",
       " 89,\n",
       " 688,\n",
       " 945,\n",
       " 1663,\n",
       " 1120,\n",
       " 1062,\n",
       " 1699,\n",
       " 375,\n",
       " 1162,\n",
       " 479,\n",
       " 1893,\n",
       " 1510,\n",
       " 799,\n",
       " 1182,\n",
       " 1237,\n",
       " 810,\n",
       " 1895,\n",
       " 1440,\n",
       " 1547,\n",
       " 181,\n",
       " 1699,\n",
       " 1758,\n",
       " 1896,\n",
       " 688,\n",
       " 1676,\n",
       " 992,\n",
       " 961,\n",
       " 1477,\n",
       " 71,\n",
       " 530,\n",
       " 1699,\n",
       " 531]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o índice de palavras\n",
    "indice_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailFeatures(\n",
    "    indice_palavras: list\n",
    ") ->np.array:\n",
    "    '''\n",
    "    Retorna a versão vectorizada do e-mail usando \n",
    "    o vector de índices de palavras.\n",
    "    \n",
    "    Cada e-mail está mapeado para um vector de n palavras\n",
    "    da lista de vocabulário. Neste vector, o valor é 1 \n",
    "    caso a palavra esteja no texto do e-mail.\n",
    "    \n",
    "    Args:\n",
    "        indices_palavras(list): Lista de indices de palavras.\n",
    "    Returns:\n",
    "        features_vetorizadas(np.array): Vector de palavras.\n",
    "    '''\n",
    "    \n",
    "    vocabulario = obterVocabulario()\n",
    "    \n",
    "    features_vetorizadas = np.zeros(len(vocabulario))\n",
    "    for i in range(0,len(vocabulario)):\n",
    "        if i in indice_palavras:\n",
    "            features_vetorizadas[i] = 1\n",
    "    \n",
    "    return features_vetorizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = emailFeatures(indice_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho do vector de palavras é: 1899\n",
      "Os elementos iguais a 1 (palavras presentes no e-mail) são: 45.0\n"
     ]
    }
   ],
   "source": [
    "print('O tamanho do vector de palavras é: {}'.format(len(features)))\n",
    "print('Os elementos iguais a 1 (palavras presentes no e-mail) são: {}'.format(features.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2 - Carregar Features pré-Calculadas e treinar SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o scipy para carregar a matriz de vectores de palavras por cada e-mails\n",
    "ficheiro_spam = io.loadmat('spamTrain.mat')\n",
    "X = np.array(ficheiro_spam['X'])\n",
    "y = np.array(ficheiro_spam['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos um vector de palavras por cada um dos e-mails calculados com o vocabulário utilizado acima.\n",
    "<br>\n",
    "Este vector é semelhante ao corrermos a função emailFeatures para diversos e-mails com texto diferente.\n",
    "<br>\n",
    "Esta matriz foi fornecida pelo prof. Andrew. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como no primeira parte do exercício 6, vamos treinar um modelo linear SVM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinoSVM(\n",
    "    X: np.array, \n",
    "    y: np.array, \n",
    "    C: float,\n",
    "    max_iter:int\n",
    ") -> SVC:\n",
    "    \n",
    "    '''\n",
    "    Treinar um classificador SVM.\n",
    "    Utilizamos a library sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X(np.array): Vector de features original.\n",
    "        y(np.array): Vector de valores target (spam/não spam).\n",
    "        C(float): Parâmetro de regularização.\n",
    "        max_iter(int): Número de iterações.\n",
    "        \n",
    "    Returns:\n",
    "        classificador_svm(sklearn.base.ClassifierMixin): classificador SVM treinado.\n",
    "    '''\n",
    "    \n",
    "    classificador_svm = SVC(C=C, kernel='linear', probability=True)\n",
    "    classificador_svm.fit(X,y.reshape(len(y),))     \n",
    "    \n",
    "    return classificador_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar um modelo com um penalty de 0.1\n",
    "C = 0.1\n",
    "model = treinoSVM(X, y, C, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever a probabilidade do e-mail ser spam.\n",
    "p = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto do modelo é: 99.825%\n"
     ]
    }
   ],
   "source": [
    "print('A taxa de acerto do modelo é: {}%'.format((p.reshape(len(p),1)==y).sum()/len(y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A taxa de acerto é bastante elevada nos dados de treino. Vamos ver a performance no conjunto de teste para perceber a capacidade de generalização.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o scipy para ler o ficheiro com os vectores de palavras do conjunto de teste\n",
    "ficheiro_spam_teste = io.loadmat('spamTest.mat')\n",
    "X_teste = np.array(ficheiro_spam_teste['Xtest'])\n",
    "y_teste = np.array(ficheiro_spam_teste['ytest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a probabilidade de spam / não spam baseada no modelo treinado \n",
    "p_teste = model.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto no conjunto de teste é 98.9%\n"
     ]
    }
   ],
   "source": [
    "print('Taxa de acerto no conjunto de teste é {}%'.format((p_teste.reshape(len(p_teste),1)==y_teste).sum()/len(y_teste)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A taxa de acerto do modelo no conjunto de validação também é bastante elevada.\n",
    "<br>\n",
    "**Vamos ver as palavras mais importantes para a decisão de considerar um e-mail spam. Como desenvolvemos um modelo linear, é relativamente fácil retirar estas parâmetros.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'our'}\n",
      "{'click'}\n",
      "{'remov'}\n",
      "{'guarante'}\n",
      "{'visit'}\n",
      "{'basenumb'}\n",
      "{'dollar'}\n",
      "{'will'}\n",
      "{'price'}\n",
      "{'pleas'}\n",
      "{'most'}\n",
      "{'nbsp'}\n",
      "{'lo'}\n",
      "{'ga'}\n",
      "{'hour'}\n"
     ]
    }
   ],
   "source": [
    "vocabulario = obterVocabulario()\n",
    "\n",
    "# Obter os coeficientos do modelo para cada feature\n",
    "pesos = model.coef_[0]\n",
    "pesos = dict(np.hstack((np.arange(1,1900).reshape(1899,1),pesos.reshape(1899,1))))\n",
    "\n",
    "# Ordenar os pesos do dicionário\n",
    "pesos = sorted(pesos.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# Verificar as palavras com mais influência\n",
    "top_15 = {}\n",
    "for i in pesos[:15]:\n",
    "    print({v for k,v in vocabulario.items() if k[0] == i[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
