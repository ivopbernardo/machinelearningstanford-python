{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os seguintes scripts são uma versão Python do curso de Machine Learning do professor Andrew Ng da universidade de Stanford leccionado na plataforma Coursera.\n",
    "\n",
    "**Nota: Todos os dados e estrutura do exercício pertencem à Universidade de Stanford**\n",
    "\n",
    "**Ressalva:** Os scripts não estão implementados de forma modular para todas as funções serem consultadas no mesmo Jupyter Notebook - ao contrário da implementação Octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o numpy para lidar com matrizes e vectores\n",
    "import numpy as np\n",
    "# Importar o pandas para ler os ficheiros \n",
    "import pandas as pd\n",
    "# Importar matplotlib para construir gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro exercício consiste em desenvolver uma regressão linear com múltiplas variáveis.\n",
    "<br>\n",
    "<br>\n",
    "Quando lidamos com múltiplas variáveis, em muitos algoritmos, é necessário estandardizar as variáveis, ou seja, coloca-las na mesma escala. No algoritmo do gradiente descendente, normalizar as variáveis faz com que o algoritmo seja mais rápido a converger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1 - Normalizar as variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados que vamos analisar são de uma empresa de imobiliário. Neste exemplo, vamos tentar prever o valor de uma casa com base em duas variáveis:\n",
    "- O tamanho de casa (em metros quadrados);\n",
    "- O número de quartos;\n",
    "<br>\n",
    "<br>\n",
    "Conseguimos desenvolver um algoritmo capaz de, dado o tamanho da casa e o número de quartos, prever o preço da propriedade com precisão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# exemplos de treino: 47 \n",
      "\n",
      "Alguns exemplos de treino da tabela: \n",
      "\n",
      "X = [1600    3] , y = 329900\n",
      "X = [2400    3] , y = 369000\n",
      "X = [1416    2] , y = 232000\n",
      "X = [3000    4] , y = 539900\n",
      "X = [1985    4] , y = 299900\n",
      "X = [1534    3] , y = 314900\n",
      "X = [1427    3] , y = 198999\n",
      "X = [1380    3] , y = 212000\n",
      "X = [1494    3] , y = 242500\n"
     ]
    }
   ],
   "source": [
    "# Ler o ficheiro de texto e criar o objecto das variáveis e o target y \n",
    "ex2_file = pd.read_csv('ex1data2.txt', header=None) \n",
    "\n",
    "X = np.array(ex2_file.iloc[:,0:2])\n",
    "\n",
    "y = np.array(ex2_file.iloc[:,2])\n",
    "\n",
    "print('# exemplos de treino: {} \\n'.format(len(X)))\n",
    "\n",
    "print('Alguns exemplos de treino da tabela: \\n')\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    print('X = {} , y = {}'.format(X[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar as variáveis - fórmula de estandardização\n",
    "\n",
    "def normalizacaoVariaveis(\n",
    "    variaveis: np.array\n",
    ") -> [np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Retorna a versão estandardizada da matriz \"variaveis\"\n",
    "    A fórmula aplicada para z é ((xi-média)/desvio padrão)\n",
    "    onde i é cada observação para a coluna nth\n",
    "    \n",
    "    Args:\n",
    "        variaveis (np.array): A matriz de n colunas para normalizar.\n",
    "        \n",
    "    Returns:\n",
    "        X_norm (np.array): Matriz de valores estandardizados.\n",
    "        media (np.array): Media de cada coluna n.\n",
    "        desvpad (np.array): Desvio padrão de cada coluna n.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    media = variaveis.mean(axis=0)\n",
    "    # para ter o mesmo resultado de estandardização do Octave, usamos os graus de liberdade = 1\n",
    "    desvpad = variaveis.std(axis=0,ddof=1)\n",
    "    X_norm = ((variaveis-media)/desvpad)\n",
    "    return X_norm, media, desvpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar a estandardização de acordo com a seguinte fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/Standardization.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A estandardização da variável Z é feita aplicando a fórmula acima:**\n",
    "<br>\n",
    "- Xi corresponde a inésima observação.\n",
    "<br>\n",
    "- μ é a média da variável.\n",
    "<br>\n",
    "- σ é o desvio padrão da variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a matriz normalizada, o vector de médias e o vector de desvios-padrão\n",
    "X, media, sigma = normalizacaoVariaveis(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a coluna de uns \n",
    "vector_uns = np.ones((len(X),1))\n",
    "# Criamos um objecto X_ext para não reescrever o objecto X\n",
    "X_ext = np.hstack((vector_uns,X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como fizemos com uma variável, vamos usar o gradiente descendente para encontrar os thetas óptimos que minimizam o erro.\n",
    "<br>\n",
    "A diferença é que agora vamos ter um novo Θ para optimizar (Θ2) - em vez de termos apenas Θ0 e Θ1.\n",
    "\n",
    "Vamos seguir uma abordagem vectorizada. Para grandes valores de m (observações) ou n (número de colunas+1, thetas para optimizar), uma abordagem vectorizada é preferencial sobre uma abordagem de ciclo já que é computacionalmente mais barata.\n",
    "\n",
    "Verificando as formulas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/Multivariate Cost Function.JPG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2 - Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do gradiente para multiplas variáveis\n",
    "# Inicializar o vector de thetas, o rácio de aprendizagem e o número de iteracções\n",
    "theta = np.zeros((3,1))\n",
    "alpha = 0.1;\n",
    "num_iters = 400;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de custo multi-variável\n",
    "def calcularCustoMulti (\n",
    "    X: np.array, \n",
    "    y:np.array , \n",
    "    theta: np.array\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    \n",
    "    Retorna a função de custo (média do erro quadrado)\n",
    "    usando o cálculo da matriz X*theta e o seu output Y\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Os valores de cada observação.\n",
    "        y (np.array): Os valores a prever.\n",
    "        theta (np.array): O peso dado a cada variável \n",
    "        que será calculado por X e representa a hipótese.\n",
    "        \n",
    "    Retorna:\n",
    "        J (int): A soma dos erros quadrados \n",
    "        - total da função de custo\n",
    "        \n",
    "    \"\"\" \n",
    "    m = len(y) \n",
    "    # Calcular hipótese\n",
    "    hipotese = np.dot(X,theta)\n",
    "    # Calcular a função de custo, usando o erro quadrado\n",
    "    J = (sum((hipotese-y.reshape(len(y),1))**2))/(2*m)\n",
    "    return J\n",
    "\n",
    "# Definir a função do gradiente multivariável\n",
    "def gradientDescentMulti(\n",
    "    X: np.array,\n",
    "    y: np.array,\n",
    "    theta: np.array,\n",
    "    alpha: float,\n",
    "    num_iters: int\n",
    ") -> [np.array, np.array]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calcula o theta óptimo baseado nas iterações \n",
    "    e histórico da função de custo.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Os valores de cada observação.\n",
    "        y (np.array): Os valores de previsão.\n",
    "        theta (np.array): O peso inicial a ser atríbuido a cada\n",
    "        variável para o cálculo da hipótese.\n",
    "        alpha(float): O rácio de aprendizagem do gradiente descendente.\n",
    "        num_iters(int): O número de iterações.\n",
    "        \n",
    "    Retorna:\n",
    "        Theta (np.array): O vector de thetas optimizado retornado\n",
    "        pela última iteração do gradiente descendente.\n",
    "        J_history (np.array): A história do erro ao longo\n",
    "        das diversas iterações do gradiente descendente.\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    m = len(y)\n",
    "    # Inicializar o vector de histórico das funções de custo\n",
    "    J_historico = np.zeros((num_iters, 1))\n",
    "    # Iterar por cada iteracao\n",
    "    for i in np.arange(0,num_iters):\n",
    "        # Calcular a hipótese\n",
    "        hipotese = np.dot(X,theta)\n",
    "        # Update theta by computing gradient\n",
    "        theta -= alpha * (1/m) * np.dot(np.transpose(X),(hipotese-y.reshape(len(y),1)))\n",
    "        # Assignar a função de custo ao element i do histórico\n",
    "        J_historico[i] = calcularCustoMulti(X,y,theta)\n",
    "    return theta, J_historico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returnar o valor do theta óptimo computado pelo gradiente descendente e respectivo histórico.\n",
    "theta, J_historico = gradientDescentMulti(X_ext,y,theta,alpha,num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao colocarmos num gráfico a convergência da função de custo, notamos alguns dados:\n",
    "<br>\n",
    "    -  A função de custo estabiliza depois de ~25 iterações;\n",
    "    -  A função de custa muda mais rápido nas primeiras iterações. Depois da 25 iteração, a mudança nos parâmetros Θ apenas trazem mudanças décimas na função de custo J;\n",
    "<br>\n",
    "Vamos usar o código seguinte para colocar num gráfico o histórico de funções de custo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Função de Custo - J - Erro Quadrado Médio')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Colocar o valor de J ao longo das iterações do gradiente descendente\n",
    "plt.plot(np.arange(0,num_iters),J_historico,c='blue')\n",
    "plt.xlabel('Número de Iterações')\n",
    "plt.ylabel('Função de Custo - J - Erro Quadrado Médio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A função de custo pode convergir para um mínimo mais lentamente se mudarmos um rácio de aprendizagem menor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qual foi o valor óptimo de thetas gerado?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta calculado pelo gradiente descendente:\n",
      " [[340412.65957447]\n",
      " [110631.04895815]\n",
      " [ -6649.47295013]]\n"
     ]
    }
   ],
   "source": [
    "print('Theta calculado pelo gradiente descendente:\\n {}'.format(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora usar os novos thetas para prever exemplos de novas casas. Por exemplo, imaginemos que temos uma nova casa que tem de área 1650 metros quadrados e tem três quartos. Dado isto, qual o preço previsto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = np.array((1, 1650, 3)).astype('float64')\n",
    "test_example[1:] = (test_example[1:].reshape(1,2)-media.reshape(1,2))/sigma.reshape(1,2)\n",
    "preco = np.dot(test_example, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço previsto para uma casa de 1650 m^2 e três quartos (usando o gradiente descendente): \n",
      " 293081 $\n"
     ]
    }
   ],
   "source": [
    "print ('Preço previsto para uma casa de 1650 m^2 e três quartos (usando o gradiente descendente): \\n {} $'.format(int(preco)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema linear, usamos o gradiente descendente para minizar a função de erro e calcularmos os nossos thetas optimizados.\n",
    "<br>\n",
    "<br> \n",
    "Mas, existe outro métodos que podemos utilizar para encontrar o erro mínimo numa regressão linear (este método acaba por também ser computacionalmente melhor já que recorre exclusivamente a vectorizações, evitando o gradiente descendente).\n",
    "Este método chama-se de Método dos Minimos Quadrados.\n",
    "<br>\n",
    "<br>\n",
    "**A fórmula utilizada para calcular o vector otimizado de thetas usando o MMQ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/NormalEquations.JPG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4 - MMQ - Metódo Mínimos Quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os dados novamente\n",
    "ex2_file = pd.read_csv('ex1data2.txt', header=None) \n",
    "X = np.array(ex2_file.iloc[:,0:2])\n",
    "y = np.array(ex2_file.iloc[:,2])\n",
    "\n",
    "m = y.size\n",
    "\n",
    "# Estandardizar\n",
    "X, _, _ = normalizacaoVariaveis(X)\n",
    "\n",
    "# Adicionar uma coluna de 1's \n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodoMinimosQuadrados(\n",
    "    X: np.array,\n",
    "    y: np.array\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculo os thetas optimos utilizado o \n",
    "    Método dos mínimos quadrados.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Os valores para cada observação.\n",
    "        y (np.array): Os valores a prever.\n",
    "        \n",
    "    Retorna:\n",
    "        Theta (np.array): O vector de thetas optimizado\n",
    "        pelo método dos mínimos quadrados.\n",
    "        \n",
    "    \"\"\" \n",
    "    # Inicializar vector de thetas\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    # Calcular thetas\n",
    "    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = metodoMinimosQuadrados(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os thetas calculados pelo método dos mínimos quadrados:\n",
      " [340412.65957447 110631.05027885  -6649.47427082]\n"
     ]
    }
   ],
   "source": [
    "print('Os thetas calculados pelo método dos mínimos quadrados:\\n {}'.format(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparamos como os thetas calculados pelo MMQ é aproximadamente o mesmo que foi retornado pela optimização do gradiente descendente. \n",
    "<br>\n",
    "E conseguimos fazer isso com muito menos linhas de código! \n",
    "<br>\n",
    "**A ressalva neste método é que apenas funciona para equações lineares - uma enorme limitação no que a funções que queremos aprender com aprendizagem de máquina - não são muitos os problemas no mundo real que podem ser aprendidos com uma simples função linear.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos a mesma previsão para a nova casa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preço previsto para uma casa de 1650 m^2 e três quartos (usando o método dos mínimos quadrados): \n",
      " 293081 $\n"
     ]
    }
   ],
   "source": [
    "exemplo_teste = np.array((1, 1650, 3)).astype('float64')\n",
    "exemplo_teste[1:] = (exemplo_teste[1:].reshape(1,2)-media.reshape(1,2))/sigma.reshape(1,2)\n",
    "preco = np.dot(exemplo_teste, theta)\n",
    "\n",
    "print ('Preço previsto para uma casa de 1650 m^2 e três quartos (usando o método dos mínimos quadrados): \\n {} $'.format(int(preco)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
